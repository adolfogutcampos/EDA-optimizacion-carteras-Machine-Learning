{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción del archivo\n",
    "\n",
    "En este archivo, vamos a importar los datos financieros por cada una de las 35 empresas del IBEX 35.\n",
    "\n",
    "En primer lugar, empezaremos importando gracias a la API de Yahoo Finance los datos de cada una de las firmas. \n",
    "\n",
    "En segundo lugar, especificaremos el intervalo temporal que queremos escoger para analizar.\n",
    "\n",
    "En tercer lugar, vamos a analizar la información resultante del dataset de cada empresa.\n",
    "\n",
    "Finalmente, guardaremos en formato .csv un dataset por cada una de las 35 compañías."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lo largo de este archivo, se ha separado en 6 principales pasos los procesos anteriores:\n",
    "Para la extracción de datos de cada una de las 35 empresas del IBEX 35, vamos a elaborar una serie de pasos:\n",
    "\n",
    "# Indice de pasos:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Paso 1: Instalar las librerias necesarias](#paso-1-instalar-las-librerias-necesarias)\n",
    "\n",
    "[Paso 2: Importar las librerias necesarias para nuestro analisis](#paso-2-importar-las-librerias-necesarias-para-nuestro-analisis)\n",
    "\n",
    "[Paso 3: Lista de empresas del IBEX 35](#paso-3-lista-de-empresas-del-ibex-35)\n",
    "\n",
    "[Paso 4: Extraccion de datasets de empresas de IBEX 35 a partir de Yahoo Finance](#paso-4-extraccion-de-datasets-de-empresas-de-ibex-35-a-partir-de-yahoo-finance)\n",
    "\n",
    "  - [Paso 4.1: Obtencion de datos financieros de las 35 empresas a partir de Yahoo Finance](#paso-41--obtencion-de-datos-financieros-de-las-35-empresas-a-partir-de-yahoo-finance)\n",
    "\n",
    "  - [Paso 4.2: Especificar los parametros de fechas a escoger](#paso-42--especificar-los-parametros-de-fechas-a-escoger)\n",
    "\n",
    "  - [Paso 4.3: Establecer el formato de fecha](#paso-43--establecer-el-formato-de-fecha)\n",
    "\n",
    "[Paso 5: Informacion acerca del dataset](#paso-5-informacion-acerca-del-dataset)\n",
    "\n",
    "  - [Paso 5.1: Filas y columnas de cada empresa](#paso-51--filas-y-columnas-de-cada-empresa)\n",
    "\n",
    "  - [Paso 5.2: Variables que vienen en los datos de las empresas a partir de Yahoo Finance](#paso-52--variables-que-vienen-en-los-datos-de-las-empresas-a-partir-de-yahoo-finance)\n",
    "\n",
    "  - [Paso 5.3: Informacion de las columnas de los datasets de las empresas](#paso-53--informacion-de-las-columnas-de-los-datasets-de-las-empresas)\n",
    "  \n",
    "[Paso 6: Guardar los datos de Yahoo Finance en archivos CSV. Uno por cada empresa del IBEX 35](#paso-6-guardar-los-datos-de-yahoo-finance-en-archivos-csv-uno-por-cada-empresa-del-ibex-35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 1: Instalar las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas\n",
    "#pip install yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 2: Importar las librerias necesarias para nuestro analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 3: Lista de empresas del IBEX 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Ibex 35 es el índice bursátil de referencia de la bolsa española conformado por los 35 valores con más liquidez que cotizan en las cuatro bolsas españolas: Madrid, Barcelona, Bilbao y Valencia. \n",
    "\n",
    "A continuación, se van a mencionar por orden alfabético el listado de empresas del IBEX 35.\n",
    "\n",
    "Esta lista está elaborada con el listado de empresas a fecha de 20/05/2024:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Número| Compañía | Etiqueta |\n",
    "|-|----------|----------|\n",
    "|1| Acciona    | ANA.MC   |\n",
    "|2| Acciona Energías    | ANE.MC   |\n",
    "|3| ACS    | ACS.MC  |\n",
    "|4| Acerinox (NO)    | ACX.MC  |\n",
    "|5| Aena\t\t\t\t|AENA.MC\n",
    "|6|Amadeus\t\t\t|AMS.MC\n",
    "|7|ArcelorMittal\t\t|MTS.MC\n",
    "|8|Banco Sabadell\t\t|SAB.MC\n",
    "|9|Banco Santander\t|SAN.MC\n",
    "|10|Bankinter\t\t\t|BKT.MC\n",
    "|11|BBVA\t\t\t\t|BBVA.MC\n",
    "|12|CaixaBank\t\t\t|CABK.MC\n",
    "|13|Cellnex\t\t\t|CLNX.MC\n",
    "|14|Colonial\t\t\t|COL.MC\n",
    "|15|Enagás\t\t\t\t|ENG.MC\n",
    "|16|Endesa\t\t\t\t|ELE.MC\n",
    "|17|Ferrovial\t\t\t|FER.MC\n",
    "|18|Fluidra\t\t\t|FDR.MC\n",
    "|19|Grifols\t\t\t|GRF.MC\n",
    "|20|IAG\t\t\t\t|IAG.MC\n",
    "|21|Iberdrola\t\t\t|IBE.MC\n",
    "|22|Indra (NO)\t\t\t\t|IDR.MC\n",
    "|23|Inditex\t\t\t|ITX.MC\n",
    "|24|Logista \t\t\t|LOG.MC\n",
    "|25|Mapfre\t\t\t\t|MAP.MC\n",
    "|26| Meliá\t\t\t\t|MEL.MC\n",
    "|27|Merlin Properties\t|MRL.MC\n",
    "|28|Naturgy\t\t\t|NTGY.MC\n",
    "|29|Redeia\t\t\t\t|RED.MC\n",
    "|30|Repsol\t\t\t\t|REP.MC\n",
    "|31|Rovi\t\t\t\t|ROVI.MC\n",
    "|32|Sacyr\t\t\t\t|SCYR.MC\n",
    "|33|Solaria\t\t\t|SLR.MC\n",
    "|34|Telefónica\t\t\t|TEF.MC\n",
    "|35|Unicaja\t\t\t|UNI.MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 4: Extraccion de datasets de empresas de IBEX 35 a partir de Yahoo Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a extraer los datos de las empresas del IBEX 35, utilizando la API proporcionada por Yahoo Finance a través de la biblioteca yfinance en Python.\n",
    "\n",
    "A continuación, vamos a especificar de nuevo la librería a pesar de haberse importado en el Paso 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La biblioteca yfinance actúa como un intermediario entre tu código Python y los servidores de Yahoo Finance, facilitando la obtención de datos financieros como precios históricos, datos en tiempo real, información de la empresa, entre otros.\n",
    "\n",
    "Tras tener importada la librería de Yahoo Finance, cabe la posibilidad de acceder entre otros a los datos financieros de las empresas del IBEX 35.\n",
    "\n",
    "En principio, tendremos en cuenta los datos en los días operativos entre las fechas de: 01/01/2018 y 20/05/2024. Es decir, 6 años y casi 5 meses.\n",
    "\n",
    "Hay que tener en cuenta que en la bolsa del IBEX 35, los días dentro de los fines de semana la bolsa está cerrada. En adicción, hay otros tantos días que no son festivos. Por lo que en cada año no habría 365 días.\n",
    "\n",
    "A continuación, se muestra:\n",
    "- Paso 4.1: Obtención de datos financieros de las 35 empresas a partir de Yahoo Finance.\n",
    "- Paso 4.2: Especificar los parámetros de fechas a escoger.\n",
    "- Paso 4.3: Establecer el formato de fecha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4.1- Obtencion de datos financieros de las 35 empresas a partir de Yahoo Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí importamos el Ticker de Yahoo Finance para cada empresa, y le asignamos una variable con su respectivo nombre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Acciona\n",
    "ANA_data = yf.Ticker('ANA.MC')\n",
    "#2 Acciona Energías\n",
    "ANE_data = yf.Ticker('ANE.MC')\n",
    "#3 ACS\n",
    "ACS_data = yf.Ticker('ACS.MC')\n",
    "#4 Acerinox\n",
    "ACX_data = yf.Ticker('ACX.MC')\n",
    "#5 Aena\n",
    "AENA_data = yf.Ticker('AENA.MC')\n",
    "#6 Amadeus\n",
    "AMS_data = yf.Ticker('AMS.MC')\n",
    "#7 ArcelorMittal\n",
    "MTS_data = yf.Ticker('MTS.MC')\n",
    "#8 Banco Sabadell\n",
    "SAB_data = yf.Ticker('SAB.MC')\n",
    "#9 Banco Santander\n",
    "SAN_data = yf.Ticker('SAN.MC')\n",
    "#10 Bankinter\n",
    "BKT_data = yf.Ticker('BKT.MC')\n",
    "#11 BBVA\n",
    "BBVA_data = yf.Ticker('BBVA.MC')\n",
    "#12 CaixaBank\n",
    "CABK_data = yf.Ticker('CABK.MC')\n",
    "#13 Cellnex\n",
    "CLNX_data = yf.Ticker('CLNX.MC')\n",
    "#14 Colonial\n",
    "COL_data = yf.Ticker('COL.MC')\n",
    "#15 Enagás\n",
    "ENG_data = yf.Ticker('ENG.MC')\n",
    "#16 Endesa\t\n",
    "ELE_data = yf.Ticker('ELE.MC')\n",
    "#17 Ferrovial\n",
    "FER_data = yf.Ticker('FER.MC')\n",
    "#18 Fluidra\n",
    "FDR_data = yf.Ticker('FDR.MC')\n",
    "#19 Grifols\n",
    "GRF_data = yf.Ticker('GRF.MC')\n",
    "#20 IAG\t\n",
    "IAG_data = yf.Ticker('IAG.MC')\n",
    "#21 Iberdrola\n",
    "IBE_data = yf.Ticker('IBE.MC')\n",
    "#22 Indra\n",
    "IDR_data = yf.Ticker('IDR.MC')\n",
    "#23 Inditex\n",
    "ITX_data = yf.Ticker('ITX.MC')\n",
    "#24 Logista\n",
    "LOG_data = yf.Ticker('LOG.MC')\n",
    "#25 Mapfre\n",
    "MAP_data = yf.Ticker('MAP.MC')\n",
    "#26 Meliá\n",
    "MEL_data = yf.Ticker('MEL.MC')\n",
    "#27 Merlin Properties\n",
    "MRL_data = yf.Ticker('MRL.MC')\n",
    "#28 Naturgy\n",
    "NTGY_data = yf.Ticker('NTGY.MC')\n",
    "#29 Redeia\n",
    "RED_data = yf.Ticker('RED.MC')\n",
    "#30 Repsol\n",
    "REP_data = yf.Ticker('REP.MC')\n",
    "#31 Rovi\n",
    "ROVI_data = yf.Ticker('ROVI.MC')\n",
    "#32 Sacyr\n",
    "SCYR_data = yf.Ticker('SCYR.MC')\n",
    "#33 Solaria\n",
    "SLR_data = yf.Ticker('SLR.MC')\n",
    "#34 Telefónica\n",
    "TEF_data = yf.Ticker('TEF.MC')\n",
    "#35 Unicaja\n",
    "UNI_data = yf.Ticker('UNI.MC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4.2- Especificar los parametros de fechas a escoger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a tener en cuenta, que el intervalo temporal a tener en cuenta para la elaboración de los análisis, tendrá por defecto las siguientes fechas:\n",
    "- La Fecha inicial se establece en el 01/01/2018\n",
    "- La Fecha final se establece en el 20/05/2024\n",
    "\n",
    "En cualquier caso, estas fechas se pueden modificar en la siguiente celda a gusto del usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "#1   fecha_inicial, la cual podemos modificar a nuestro antojo\n",
    "fecha_inicial = '2018-01-01'\n",
    "\n",
    "#2   fecha_final, la cual podemos modificar a nuestro antojo\n",
    "fecha_final = '2024-05-20'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte, dejamos especificados los parámetros de start y end, con la fecha inicial y final establecida en la celda anterior.\n",
    "\n",
    "A continuación, mostramos como quedaría el filtrado de las fechas mediante la aplicación para la empresa ACS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:00:00+01:00</th>\n",
       "      <td>21.370347</td>\n",
       "      <td>21.370347</td>\n",
       "      <td>20.997152</td>\n",
       "      <td>21.118277</td>\n",
       "      <td>1416627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03 00:00:00+01:00</th>\n",
       "      <td>21.213212</td>\n",
       "      <td>21.383439</td>\n",
       "      <td>21.173927</td>\n",
       "      <td>21.259043</td>\n",
       "      <td>454050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04 00:00:00+01:00</th>\n",
       "      <td>21.396540</td>\n",
       "      <td>21.946512</td>\n",
       "      <td>21.376898</td>\n",
       "      <td>21.926870</td>\n",
       "      <td>1385247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05 00:00:00+01:00</th>\n",
       "      <td>21.959604</td>\n",
       "      <td>22.254232</td>\n",
       "      <td>21.874489</td>\n",
       "      <td>22.221495</td>\n",
       "      <td>584567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08 00:00:00+01:00</th>\n",
       "      <td>22.260779</td>\n",
       "      <td>22.326252</td>\n",
       "      <td>22.031624</td>\n",
       "      <td>22.031624</td>\n",
       "      <td>509748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-13 00:00:00+02:00</th>\n",
       "      <td>38.860001</td>\n",
       "      <td>39.419998</td>\n",
       "      <td>38.740002</td>\n",
       "      <td>39.360001</td>\n",
       "      <td>403195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-14 00:00:00+02:00</th>\n",
       "      <td>39.200001</td>\n",
       "      <td>39.580002</td>\n",
       "      <td>39.060001</td>\n",
       "      <td>39.439999</td>\n",
       "      <td>485238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-15 00:00:00+02:00</th>\n",
       "      <td>39.419998</td>\n",
       "      <td>39.599998</td>\n",
       "      <td>38.740002</td>\n",
       "      <td>39.480000</td>\n",
       "      <td>736659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-16 00:00:00+02:00</th>\n",
       "      <td>39.540001</td>\n",
       "      <td>39.820000</td>\n",
       "      <td>39.320000</td>\n",
       "      <td>39.759998</td>\n",
       "      <td>552398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-17 00:00:00+02:00</th>\n",
       "      <td>39.560001</td>\n",
       "      <td>40.080002</td>\n",
       "      <td>39.520000</td>\n",
       "      <td>39.840000</td>\n",
       "      <td>535216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1631 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Open       High        Low      Close  \\\n",
       "Date                                                                    \n",
       "2018-01-02 00:00:00+01:00  21.370347  21.370347  20.997152  21.118277   \n",
       "2018-01-03 00:00:00+01:00  21.213212  21.383439  21.173927  21.259043   \n",
       "2018-01-04 00:00:00+01:00  21.396540  21.946512  21.376898  21.926870   \n",
       "2018-01-05 00:00:00+01:00  21.959604  22.254232  21.874489  22.221495   \n",
       "2018-01-08 00:00:00+01:00  22.260779  22.326252  22.031624  22.031624   \n",
       "...                              ...        ...        ...        ...   \n",
       "2024-05-13 00:00:00+02:00  38.860001  39.419998  38.740002  39.360001   \n",
       "2024-05-14 00:00:00+02:00  39.200001  39.580002  39.060001  39.439999   \n",
       "2024-05-15 00:00:00+02:00  39.419998  39.599998  38.740002  39.480000   \n",
       "2024-05-16 00:00:00+02:00  39.540001  39.820000  39.320000  39.759998   \n",
       "2024-05-17 00:00:00+02:00  39.560001  40.080002  39.520000  39.840000   \n",
       "\n",
       "                            Volume  Dividends  Stock Splits  \n",
       "Date                                                         \n",
       "2018-01-02 00:00:00+01:00  1416627        0.0           0.0  \n",
       "2018-01-03 00:00:00+01:00   454050        0.0           0.0  \n",
       "2018-01-04 00:00:00+01:00  1385247        0.0           0.0  \n",
       "2018-01-05 00:00:00+01:00   584567        0.0           0.0  \n",
       "2018-01-08 00:00:00+01:00   509748        0.0           0.0  \n",
       "...                            ...        ...           ...  \n",
       "2024-05-13 00:00:00+02:00   403195        0.0           0.0  \n",
       "2024-05-14 00:00:00+02:00   485238        0.0           0.0  \n",
       "2024-05-15 00:00:00+02:00   736659        0.0           0.0  \n",
       "2024-05-16 00:00:00+02:00   552398        0.0           0.0  \n",
       "2024-05-17 00:00:00+02:00   535216        0.0           0.0  \n",
       "\n",
       "[1631 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACS_df = ACS_data.history(start=fecha_inicial, end=fecha_final)\n",
    "ACS_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En adicción, se muestra el mismo procedimiento para cada empresa del IBEX 35:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANA_df = ANA_data.history(start=fecha_inicial, end=fecha_final)\n",
    "ANE_df = ANE_data.history(start=fecha_inicial, end=fecha_final)\n",
    "ACS_df = ACS_data.history(start=fecha_inicial, end=fecha_final)\n",
    "ACX_df = ACX_data.history(start=fecha_inicial, end=fecha_final)\n",
    "AENA_df = AENA_data.history(start=fecha_inicial, end=fecha_final)\n",
    "AMS_df = AMS_data.history(start=fecha_inicial, end=fecha_final)\n",
    "MTS_df = MTS_data.history(start=fecha_inicial, end=fecha_final)\n",
    "SAB_df = SAB_data.history(start=fecha_inicial, end=fecha_final)\n",
    "SAN_df = SAN_data.history(start=fecha_inicial, end=fecha_final)\n",
    "BKT_df = BKT_data.history(start=fecha_inicial, end=fecha_final)\n",
    "BBVA_df = BBVA_data.history(start=fecha_inicial, end=fecha_final)\n",
    "CABK_df = CABK_data.history(start=fecha_inicial, end=fecha_final)\n",
    "CLNX_df = CLNX_data.history(start=fecha_inicial, end=fecha_final)\n",
    "COL_df = COL_data.history(start=fecha_inicial, end=fecha_final)\n",
    "ENG_df = ENG_data.history(start=fecha_inicial, end=fecha_final)\n",
    "ELE_df = ELE_data.history(start=fecha_inicial, end=fecha_final)\n",
    "FER_df = FER_data.history(start=fecha_inicial, end=fecha_final)\n",
    "FDR_df = FDR_data.history(start=fecha_inicial, end=fecha_final)\n",
    "GRF_df = GRF_data.history(start=fecha_inicial, end=fecha_final)\n",
    "IAG_df = IAG_data.history(start=fecha_inicial, end=fecha_final)\n",
    "IBE_df = IBE_data.history(start=fecha_inicial, end=fecha_final)\n",
    "IDR_df = IDR_data.history(start=fecha_inicial, end=fecha_final)\n",
    "ITX_df = ITX_data.history(start=fecha_inicial, end=fecha_final)\n",
    "LOG_df = LOG_data.history(start=fecha_inicial, end=fecha_final)\n",
    "MAP_df = MAP_data.history(start=fecha_inicial, end=fecha_final)\n",
    "MEL_df = MEL_data.history(start=fecha_inicial, end=fecha_final)\n",
    "MRL_df = MRL_data.history(start=fecha_inicial, end=fecha_final)\n",
    "NTGY_df = NTGY_data.history(start=fecha_inicial, end=fecha_final)\n",
    "RED_df = RED_data.history(start=fecha_inicial, end=fecha_final)\n",
    "REP_df = REP_data.history(start=fecha_inicial, end=fecha_final)\n",
    "ROVI_df = ROVI_data.history(start=fecha_inicial, end=fecha_final)\n",
    "SCYR_df = SCYR_data.history(start=fecha_inicial, end=fecha_final)\n",
    "SLR_df = SLR_data.history(start=fecha_inicial, end=fecha_final)\n",
    "TEF_df = TEF_data.history(start=fecha_inicial, end=fecha_final)\n",
    "UNI_df = UNI_data.history(start=fecha_inicial, end=fecha_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4.3- Establecer el formato de fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:00:00+01:00</th>\n",
       "      <td>21.370347</td>\n",
       "      <td>21.370347</td>\n",
       "      <td>20.997152</td>\n",
       "      <td>21.118277</td>\n",
       "      <td>1416627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03 00:00:00+01:00</th>\n",
       "      <td>21.213212</td>\n",
       "      <td>21.383439</td>\n",
       "      <td>21.173927</td>\n",
       "      <td>21.259043</td>\n",
       "      <td>454050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04 00:00:00+01:00</th>\n",
       "      <td>21.396540</td>\n",
       "      <td>21.946512</td>\n",
       "      <td>21.376898</td>\n",
       "      <td>21.926870</td>\n",
       "      <td>1385247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05 00:00:00+01:00</th>\n",
       "      <td>21.959604</td>\n",
       "      <td>22.254232</td>\n",
       "      <td>21.874489</td>\n",
       "      <td>22.221495</td>\n",
       "      <td>584567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08 00:00:00+01:00</th>\n",
       "      <td>22.260779</td>\n",
       "      <td>22.326252</td>\n",
       "      <td>22.031624</td>\n",
       "      <td>22.031624</td>\n",
       "      <td>509748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-13 00:00:00+02:00</th>\n",
       "      <td>38.860001</td>\n",
       "      <td>39.419998</td>\n",
       "      <td>38.740002</td>\n",
       "      <td>39.360001</td>\n",
       "      <td>403195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-14 00:00:00+02:00</th>\n",
       "      <td>39.200001</td>\n",
       "      <td>39.580002</td>\n",
       "      <td>39.060001</td>\n",
       "      <td>39.439999</td>\n",
       "      <td>485238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-15 00:00:00+02:00</th>\n",
       "      <td>39.419998</td>\n",
       "      <td>39.599998</td>\n",
       "      <td>38.740002</td>\n",
       "      <td>39.480000</td>\n",
       "      <td>736659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-16 00:00:00+02:00</th>\n",
       "      <td>39.540001</td>\n",
       "      <td>39.820000</td>\n",
       "      <td>39.320000</td>\n",
       "      <td>39.759998</td>\n",
       "      <td>552398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-17 00:00:00+02:00</th>\n",
       "      <td>39.560001</td>\n",
       "      <td>40.080002</td>\n",
       "      <td>39.520000</td>\n",
       "      <td>39.840000</td>\n",
       "      <td>535216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1631 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Open       High        Low      Close  \\\n",
       "Date                                                                    \n",
       "2018-01-02 00:00:00+01:00  21.370347  21.370347  20.997152  21.118277   \n",
       "2018-01-03 00:00:00+01:00  21.213212  21.383439  21.173927  21.259043   \n",
       "2018-01-04 00:00:00+01:00  21.396540  21.946512  21.376898  21.926870   \n",
       "2018-01-05 00:00:00+01:00  21.959604  22.254232  21.874489  22.221495   \n",
       "2018-01-08 00:00:00+01:00  22.260779  22.326252  22.031624  22.031624   \n",
       "...                              ...        ...        ...        ...   \n",
       "2024-05-13 00:00:00+02:00  38.860001  39.419998  38.740002  39.360001   \n",
       "2024-05-14 00:00:00+02:00  39.200001  39.580002  39.060001  39.439999   \n",
       "2024-05-15 00:00:00+02:00  39.419998  39.599998  38.740002  39.480000   \n",
       "2024-05-16 00:00:00+02:00  39.540001  39.820000  39.320000  39.759998   \n",
       "2024-05-17 00:00:00+02:00  39.560001  40.080002  39.520000  39.840000   \n",
       "\n",
       "                            Volume  Dividends  Stock Splits  \n",
       "Date                                                         \n",
       "2018-01-02 00:00:00+01:00  1416627        0.0           0.0  \n",
       "2018-01-03 00:00:00+01:00   454050        0.0           0.0  \n",
       "2018-01-04 00:00:00+01:00  1385247        0.0           0.0  \n",
       "2018-01-05 00:00:00+01:00   584567        0.0           0.0  \n",
       "2018-01-08 00:00:00+01:00   509748        0.0           0.0  \n",
       "...                            ...        ...           ...  \n",
       "2024-05-13 00:00:00+02:00   403195        0.0           0.0  \n",
       "2024-05-14 00:00:00+02:00   485238        0.0           0.0  \n",
       "2024-05-15 00:00:00+02:00   736659        0.0           0.0  \n",
       "2024-05-16 00:00:00+02:00   552398        0.0           0.0  \n",
       "2024-05-17 00:00:00+02:00   535216        0.0           0.0  \n",
       "\n",
       "[1631 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACS_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, vamos a establecer el formato de fecha %Y-%m-%d , que es básicamente el YYYY-MM-DD. \n",
    "\n",
    "Este formato no está asociado específicamente a un país en particular, sino que es un estándar de formato de fecha ampliamente utilizado en la programación y en sistemas informáticos en general. Es parte de la especificación de formateo de fecha y hora de la biblioteca estándar de Python y se utiliza en muchas otras herramientas y lenguajes de programación.\n",
    "\n",
    "A continuación, lo aplicamos a los dataframes de las 35 empresas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANA_df.index = ANA_df.index.strftime('%Y-%m-%d')\n",
    "ANE_df.index = ANE_df.index.strftime('%Y-%m-%d')\n",
    "ACS_df.index = ACS_df.index.strftime('%Y-%m-%d')\n",
    "ACX_df.index = ACX_df.index.strftime('%Y-%m-%d')\n",
    "AENA_df.index = AENA_df.index.strftime('%Y-%m-%d')\n",
    "AMS_df.index = AMS_df.index.strftime('%Y-%m-%d')\n",
    "MTS_df.index = MTS_df.index.strftime('%Y-%m-%d')\n",
    "SAB_df.index = SAB_df.index.strftime('%Y-%m-%d')\n",
    "SAN_df.index = SAN_df.index.strftime('%Y-%m-%d')\n",
    "BKT_df.index = BKT_df.index.strftime('%Y-%m-%d')\n",
    "BBVA_df.index = BBVA_df.index.strftime('%Y-%m-%d')\n",
    "CABK_df.index = CABK_df.index.strftime('%Y-%m-%d')\n",
    "CLNX_df.index = CLNX_df.index.strftime('%Y-%m-%d')\n",
    "COL_df.index = COL_df.index.strftime('%Y-%m-%d')\n",
    "ENG_df.index = ENG_df.index.strftime('%Y-%m-%d')\n",
    "ELE_df.index = ELE_df.index.strftime('%Y-%m-%d')\n",
    "FER_df.index = FER_df.index.strftime('%Y-%m-%d')\n",
    "FDR_df.index = FDR_df.index.strftime('%Y-%m-%d')\n",
    "GRF_df.index = GRF_df.index.strftime('%Y-%m-%d')\n",
    "IAG_df.index = IAG_df.index.strftime('%Y-%m-%d')\n",
    "IBE_df.index = IBE_df.index.strftime('%Y-%m-%d')\n",
    "IDR_df.index = IDR_df.index.strftime('%Y-%m-%d')\n",
    "ITX_df.index = ITX_df.index.strftime('%Y-%m-%d')\n",
    "LOG_df.index = LOG_df.index.strftime('%Y-%m-%d')\n",
    "MAP_df.index = MAP_df.index.strftime('%Y-%m-%d')\n",
    "MEL_df.index = MEL_df.index.strftime('%Y-%m-%d')\n",
    "MRL_df.index = MRL_df.index.strftime('%Y-%m-%d')\n",
    "NTGY_df.index = NTGY_df.index.strftime('%Y-%m-%d')\n",
    "RED_df.index = RED_df.index.strftime('%Y-%m-%d')\n",
    "REP_df.index = REP_df.index.strftime('%Y-%m-%d')\n",
    "ROVI_df.index = ROVI_df.index.strftime('%Y-%m-%d')\n",
    "SCYR_df.index = SCYR_df.index.strftime('%Y-%m-%d')\n",
    "SLR_df.index = SLR_df.index.strftime('%Y-%m-%d')\n",
    "TEF_df.index = TEF_df.index.strftime('%Y-%m-%d')\n",
    "UNI_df.index = UNI_df.index.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma que quede cada empresa de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>21.370347</td>\n",
       "      <td>21.370347</td>\n",
       "      <td>20.997152</td>\n",
       "      <td>21.118277</td>\n",
       "      <td>1416627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>21.213212</td>\n",
       "      <td>21.383439</td>\n",
       "      <td>21.173927</td>\n",
       "      <td>21.259043</td>\n",
       "      <td>454050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>21.396540</td>\n",
       "      <td>21.946512</td>\n",
       "      <td>21.376898</td>\n",
       "      <td>21.926870</td>\n",
       "      <td>1385247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>21.959604</td>\n",
       "      <td>22.254232</td>\n",
       "      <td>21.874489</td>\n",
       "      <td>22.221495</td>\n",
       "      <td>584567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>22.260779</td>\n",
       "      <td>22.326252</td>\n",
       "      <td>22.031624</td>\n",
       "      <td>22.031624</td>\n",
       "      <td>509748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-13</th>\n",
       "      <td>38.860001</td>\n",
       "      <td>39.419998</td>\n",
       "      <td>38.740002</td>\n",
       "      <td>39.360001</td>\n",
       "      <td>403195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-14</th>\n",
       "      <td>39.200001</td>\n",
       "      <td>39.580002</td>\n",
       "      <td>39.060001</td>\n",
       "      <td>39.439999</td>\n",
       "      <td>485238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-15</th>\n",
       "      <td>39.419998</td>\n",
       "      <td>39.599998</td>\n",
       "      <td>38.740002</td>\n",
       "      <td>39.480000</td>\n",
       "      <td>736659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-16</th>\n",
       "      <td>39.540001</td>\n",
       "      <td>39.820000</td>\n",
       "      <td>39.320000</td>\n",
       "      <td>39.759998</td>\n",
       "      <td>552398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-17</th>\n",
       "      <td>39.560001</td>\n",
       "      <td>40.080002</td>\n",
       "      <td>39.520000</td>\n",
       "      <td>39.840000</td>\n",
       "      <td>535216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1631 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close   Volume  Dividends  \\\n",
       "Date                                                                         \n",
       "2018-01-02  21.370347  21.370347  20.997152  21.118277  1416627        0.0   \n",
       "2018-01-03  21.213212  21.383439  21.173927  21.259043   454050        0.0   \n",
       "2018-01-04  21.396540  21.946512  21.376898  21.926870  1385247        0.0   \n",
       "2018-01-05  21.959604  22.254232  21.874489  22.221495   584567        0.0   \n",
       "2018-01-08  22.260779  22.326252  22.031624  22.031624   509748        0.0   \n",
       "...               ...        ...        ...        ...      ...        ...   \n",
       "2024-05-13  38.860001  39.419998  38.740002  39.360001   403195        0.0   \n",
       "2024-05-14  39.200001  39.580002  39.060001  39.439999   485238        0.0   \n",
       "2024-05-15  39.419998  39.599998  38.740002  39.480000   736659        0.0   \n",
       "2024-05-16  39.540001  39.820000  39.320000  39.759998   552398        0.0   \n",
       "2024-05-17  39.560001  40.080002  39.520000  39.840000   535216        0.0   \n",
       "\n",
       "            Stock Splits  \n",
       "Date                      \n",
       "2018-01-02           0.0  \n",
       "2018-01-03           0.0  \n",
       "2018-01-04           0.0  \n",
       "2018-01-05           0.0  \n",
       "2018-01-08           0.0  \n",
       "...                  ...  \n",
       "2024-05-13           0.0  \n",
       "2024-05-14           0.0  \n",
       "2024-05-15           0.0  \n",
       "2024-05-16           0.0  \n",
       "2024-05-17           0.0  \n",
       "\n",
       "[1631 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACS_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 5: Informacion acerca del dataset\n",
    "\n",
    "Vamos a analizar la información que nos viene de las 35 compañías."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5.1- Filas y columnas de cada empresa\n",
    "\n",
    "En primer, lugar tenemos las siguientes filas y columnas para ACS como ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1631, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACS_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos un total de:\n",
    "- 1631 filas\n",
    "- el index de 'Date' y 7 columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el output de la siguiente celda, vamos a ver las filas y columnas de todas las compañías del IBEX 35:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ANA_df: (1631, 7)\n",
      "2. ANE_df: (737, 7)\n",
      "3. ACS_df: (1631, 7)\n",
      "4. ACX_df: (1631, 7)\n",
      "5. AENA_df: (1631, 7)\n",
      "6. AMS_df: (1631, 7)\n",
      "7. MTS_df: (1631, 7)\n",
      "8. SAB_df: (1631, 7)\n",
      "9. SAN_df: (1631, 7)\n",
      "10. BKT_df: (1631, 7)\n",
      "11. BBVA_df: (1631, 7)\n",
      "12. CABK_df: (1631, 7)\n",
      "13. CLNX_df: (1631, 7)\n",
      "14. COL_df: (1631, 7)\n",
      "15. ENG_df: (1631, 7)\n",
      "16. ELE_df: (1631, 7)\n",
      "17. FER_df: (1631, 7)\n",
      "18. FDR_df: (1631, 7)\n",
      "19. GRF_df: (1631, 7)\n",
      "20. IAG_df: (1631, 7)\n",
      "21. IBE_df: (1631, 7)\n",
      "22. IDR_df: (1631, 7)\n",
      "23. ITX_df: (1631, 7)\n",
      "24. LOG_df: (1631, 7)\n",
      "25. MAP_df: (1631, 7)\n",
      "26. MEL_df: (1631, 7)\n",
      "27. MRL_df: (1631, 7)\n",
      "28. NTGY_df: (1631, 7)\n",
      "29. RED_df: (1631, 7)\n",
      "30. REP_df: (1631, 7)\n",
      "31. ROVI_df: (1631, 7)\n",
      "32. SCYR_df: (1631, 7)\n",
      "33. SLR_df: (1631, 7)\n",
      "34. TEF_df: (1631, 7)\n",
      "35. UNI_df: (1631, 7)\n"
     ]
    }
   ],
   "source": [
    "dataframes_dict = {\n",
    "    \"ANA_df\": ANA_df,\n",
    "    \"ANE_df\": ANE_df,\n",
    "    \"ACS_df\": ACS_df,\n",
    "    \"ACX_df\": ACX_df,\n",
    "    \"AENA_df\": AENA_df,\n",
    "    \"AMS_df\": AMS_df,\n",
    "    \"MTS_df\": MTS_df,\n",
    "    \"SAB_df\": SAB_df,\n",
    "    \"SAN_df\": SAN_df,\n",
    "    \"BKT_df\": BKT_df,\n",
    "    \"BBVA_df\": BBVA_df,\n",
    "    \"CABK_df\": CABK_df,\n",
    "    \"CLNX_df\": CLNX_df,\n",
    "    \"COL_df\": COL_df,\n",
    "    \"ENG_df\": ENG_df,\n",
    "    \"ELE_df\": ELE_df,\n",
    "    \"FER_df\": FER_df,\n",
    "    \"FDR_df\": FDR_df,\n",
    "    \"GRF_df\": GRF_df,\n",
    "    \"IAG_df\": IAG_df,\n",
    "    \"IBE_df\": IBE_df,\n",
    "    \"IDR_df\": IDR_df,\n",
    "    \"ITX_df\": ITX_df,\n",
    "    \"LOG_df\": LOG_df,\n",
    "    \"MAP_df\": MAP_df,\n",
    "    \"MEL_df\": MEL_df,\n",
    "    \"MRL_df\": MRL_df,\n",
    "    \"NTGY_df\": NTGY_df,\n",
    "    \"RED_df\": RED_df,\n",
    "    \"REP_df\": REP_df,\n",
    "    \"ROVI_df\": ROVI_df,\n",
    "    \"SCYR_df\": SCYR_df,\n",
    "    \"SLR_df\": SLR_df,\n",
    "    \"TEF_df\": TEF_df,\n",
    "    \"UNI_df\": UNI_df\n",
    "}\n",
    "\n",
    "for i, (df_name, df) in enumerate(dataframes_dict.items(), start=1):\n",
    "    print(f\"{i}. {df_name}: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De entre las 35 compañías, se ha identificado una empresa con menos filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(737, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANE_df.shape    # Acciona Energia tiene menor cantidad de filas.\n",
    "#Salió a bolsa en agosto del 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5.2- Variables que vienen en los datos de las empresas a partir de Yahoo Finance\n",
    "\n",
    "En segundo lugar, desde Yahoo Finance, estamos importando de cada empresa las siguientes variables:\n",
    "\n",
    "Como podemos observar, hay 7 columnas que vamos a explicar brevemente.\n",
    "\n",
    "1- Date (index)\n",
    "\n",
    "Esta columna la hemos creado previamente. Date(fecha) se refiere al punto específico en el tiempo en el que se lleva a cabo una transacción o una serie de transacciones en el mercado de valores. La fecha se indica generalmente en un formato estándar de día, mes y año y es crucial para el registro preciso de las operaciones financieras.\n",
    "\n",
    "2- Open\n",
    "\n",
    "Open (Apertura) describe el precio al que una acción comienza a ser negociada al inicio de un periodo determinado de cotización, como el inicio de una jornada de trading o el inicio de un intervalo de tiempo específico.\n",
    "\n",
    "3- High\n",
    "\n",
    "High (Alto) se refiere al precio más alto alcanzado por una acción durante el periodo de tiempo analizado. Representa el punto máximo de valoración alcanzado por la acción en el mercado durante ese periodo.\n",
    "\n",
    "4- Low\n",
    "\n",
    "Low (Baja) es el precio más bajo registrado para una acción durante el periodo de tiempo en cuestión. Indica el nivel mínimo de valoración al que la acción ha llegado en el mercado durante ese periodo de tiempo.\n",
    "\n",
    "5- Close\n",
    "\n",
    "Close (Cierre) describe el precio al que una acción finaliza su cotización al final de un periodo específico, como el cierre de una jornada de trading o el final de un intervalo de tiempo determinado.\n",
    "\n",
    "6- Volume\n",
    "\n",
    "Volume (Volumen) indica el número total de acciones que se han negociado durante un periodo de tiempo específico. El volumen es un indicador clave de la actividad de trading en el mercado de valores y puede proporcionar información sobre el interés y la liquidez de una acción en particular.\n",
    "\n",
    "7- Dividends\n",
    "\n",
    "Dividends (Dividendos) indica los dividendos pagados por las acciones de la empresa en la fecha correspondiente, si los hubiera. Los dividendos representan los pagos periódicos realizados a los accionistas como una distribución de las ganancias de la empresa.\n",
    "\n",
    "8- Stock Splits\n",
    " \n",
    "Stock Splits (División de acciones) indica si se produjeron divisiones de acciones de ACS en la fecha indicada. Un split de acciones implica la división de las acciones existentes en múltiples acciones nuevas, generalmente con el objetivo de ajustar el precio por acción y hacerlas más accesibles para los inversores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5.3- Informacion de las columnas de los datasets de las empresas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En tercer lugar, vamos a obtener más información de las columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACS_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1631 entries, 2018-01-02 to 2024-05-17\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Open          1631 non-null   float64\n",
      " 1   High          1631 non-null   float64\n",
      " 2   Low           1631 non-null   float64\n",
      " 3   Close         1631 non-null   float64\n",
      " 4   Volume        1631 non-null   int64  \n",
      " 5   Dividends     1631 non-null   float64\n",
      " 6   Stock Splits  1631 non-null   float64\n",
      "dtypes: float64(6), int64(1)\n",
      "memory usage: 101.9+ KB\n"
     ]
    }
   ],
   "source": [
    "ACS_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobar si hay valores NaN en las columnas de los datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open            0\n",
       "High            0\n",
       "Low             0\n",
       "Close           0\n",
       "Volume          0\n",
       "Dividends       0\n",
       "Stock Splits    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACS_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y a continuación, si los hay a lo largo de todo el dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Open  High  Low  Close  Volume  Dividends  Stock Splits\n",
      "ANA_df      0     0    0      0       0          0             0\n",
      "ANE_df      0     0    0      0       0          0             0\n",
      "ACS_df      0     0    0      0       0          0             0\n",
      "ACX_df      0     0    0      0       0          0             0\n",
      "AENA_df     0     0    0      0       0          0             0\n",
      "AMS_df      0     0    0      0       0          0             0\n",
      "MTS_df      0     0    0      0       0          0             0\n",
      "SAB_df      0     0    0      0       0          0             0\n",
      "SAN_df      0     0    0      0       0          0             0\n",
      "BKT_df      0     0    0      0       0          0             0\n",
      "BBVA_df     0     0    0      0       0          0             0\n",
      "CABK_df     0     0    0      0       0          0             0\n",
      "CLNX_df     0     0    0      0       0          0             0\n",
      "COL_df      0     0    0      0       0          0             0\n",
      "ENG_df      0     0    0      0       0          0             0\n",
      "ELE_df      0     0    0      0       0          0             0\n",
      "FER_df      0     0    0      0       0          0             0\n",
      "FDR_df      0     0    0      0       0          0             0\n",
      "GRF_df      0     0    0      0       0          0             0\n",
      "IAG_df      0     0    0      0       0          0             0\n",
      "IBE_df      0     0    0      0       0          0             0\n",
      "IDR_df      0     0    0      0       0          0             0\n",
      "ITX_df      0     0    0      0       0          0             0\n",
      "LOG_df      0     0    0      0       0          0             0\n",
      "MAP_df      0     0    0      0       0          0             0\n",
      "MEL_df      0     0    0      0       0          0             0\n",
      "MRL_df      0     0    0      0       0          0             0\n",
      "NTGY_df     0     0    0      0       0          0             0\n",
      "RED_df      0     0    0      0       0          0             0\n",
      "REP_df      0     0    0      0       0          0             0\n",
      "ROVI_df     0     0    0      0       0          0             0\n",
      "SCYR_df     0     0    0      0       0          0             0\n",
      "SLR_df      0     0    0      0       0          0             0\n",
      "TEF_df      0     0    0      0       0          0             0\n",
      "UNI_df      0     0    0      0       0          0             0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Diccionario para mapear el nombre del DataFrame con su respectivo DataFrame\n",
    "dataframes_dict = {\n",
    "    \"ANA_df\": ANA_df,\n",
    "    \"ANE_df\": ANE_df,\n",
    "    \"ACS_df\": ACS_df,\n",
    "    \"ACX_df\": ACX_df,\n",
    "    \"AENA_df\": AENA_df,\n",
    "    \"AMS_df\": AMS_df,\n",
    "    \"MTS_df\": MTS_df,\n",
    "    \"SAB_df\": SAB_df,\n",
    "    \"SAN_df\": SAN_df,\n",
    "    \"BKT_df\": BKT_df,\n",
    "    \"BBVA_df\": BBVA_df,\n",
    "    \"CABK_df\": CABK_df,\n",
    "    \"CLNX_df\": CLNX_df,\n",
    "    \"COL_df\": COL_df,\n",
    "    \"ENG_df\": ENG_df,\n",
    "    \"ELE_df\": ELE_df,\n",
    "    \"FER_df\": FER_df,\n",
    "    \"FDR_df\": FDR_df,\n",
    "    \"GRF_df\": GRF_df,\n",
    "    \"IAG_df\": IAG_df,\n",
    "    \"IBE_df\": IBE_df,\n",
    "    \"IDR_df\": IDR_df,\n",
    "    \"ITX_df\": ITX_df,\n",
    "    \"LOG_df\": LOG_df,\n",
    "    \"MAP_df\": MAP_df,\n",
    "    \"MEL_df\": MEL_df,\n",
    "    \"MRL_df\": MRL_df,\n",
    "    \"NTGY_df\": NTGY_df,\n",
    "    \"RED_df\": RED_df,\n",
    "    \"REP_df\": REP_df,\n",
    "    \"ROVI_df\": ROVI_df,\n",
    "    \"SCYR_df\": SCYR_df,\n",
    "    \"SLR_df\": SLR_df,\n",
    "    \"TEF_df\": TEF_df,\n",
    "    \"UNI_df\": UNI_df\n",
    "}\n",
    "\n",
    "na_counts_dict = {}\n",
    "\n",
    "for df_name, df in dataframes_dict.items():\n",
    "    na_counts_dict[df_name] = df.isna().sum()\n",
    "\n",
    "na_counts_df = pd.DataFrame(na_counts_dict)\n",
    "\n",
    "# Transponer el df para tener los DataFrames en columnas verticales\n",
    "na_counts_df = na_counts_df.transpose()\n",
    "\n",
    "print(na_counts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, no hay valores nulos, por lo que no será necesaria una limpieza de los datasets.\n",
    "\n",
    "Podemos confirmar que los datos que provienen de Yahoo Finance vienen de forma relativamente limpia para poder analizarlos posteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 6: Guardar los datos de Yahoo Finance en archivos CSV. Uno por cada empresa del IBEX 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras haber filtrado los 35 datasets, vamos a proceder a guardar cada dataset en archivos .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANA_df.to_csv('../Data/ANA_dataset.csv')\n",
    "#ANE_df.to_csv('../Data/ANE_dataset.csv')\n",
    "#ACS_df.to_csv('../Data/ACS_dataset.csv')\n",
    "#ACX_df.to_csv('../Data/ACX_dataset.csv')\n",
    "#AENA_df.to_csv('../Data/AENA_dataset.csv')\n",
    "#AMS_df.to_csv('../Data/AMS_dataset.csv')\n",
    "#MTS_df.to_csv('../Data/MTS_dataset.csv')\n",
    "#SAB_df.to_csv('../Data/SAB_dataset.csv')\n",
    "#SAN_df.to_csv('../Data/SAN_dataset.csv')\n",
    "#BKT_df.to_csv('../Data/BKT_dataset.csv')\n",
    "#BBVA_df.to_csv('../Data/BBVA_dataset.csv')\n",
    "#CABK_df.to_csv('../Data/CABK_dataset.csv')\n",
    "#CLNX_df.to_csv('../Data/CLNX_dataset.csv')\n",
    "#COL_df.to_csv('../Data/COL_dataset.csv')\n",
    "#ENG_df.to_csv('../Data/ENG_dataset.csv')\n",
    "#ELE_df.to_csv('../Data/ELE_dataset.csv')\n",
    "#FER_df.to_csv('../Data/FER_dataset.csv')\n",
    "#FDR_df.to_csv('../Data/FDR_dataset.csv')\n",
    "#GRF_df.to_csv('../Data/GRF_dataset.csv')\n",
    "#IAG_df.to_csv('../Data/IAG_dataset.csv')\n",
    "#IBE_df.to_csv('../Data/IBE_dataset.csv')\n",
    "#IDR_df.to_csv('../Data/IDR_dataset.csv')\n",
    "#ITX_df.to_csv('../Data/ITX_dataset.csv')\n",
    "#LOG_df.to_csv('../Data/LOG_dataset.csv')\n",
    "#MAP_df.to_csv('../Data/MAP_dataset.csv')\n",
    "#MEL_df.to_csv('../Data/MEL_dataset.csv')\n",
    "#MRL_df.to_csv('../Data/MRL_dataset.csv')\n",
    "#NTGY_df.to_csv('../Data/NTGY_dataset.csv')\n",
    "#RED_df.to_csv('../Data/RED_dataset.csv')\n",
    "#REP_df.to_csv('../Data/REP_dataset.csv')\n",
    "#ROVI_df.to_csv('../Data/ROVI_dataset.csv')\n",
    "#SCYR_df.to_csv('../Data/SCYR_dataset.csv')\n",
    "#SLR_df.to_csv('../Data/SLR_dataset.csv')\n",
    "#TEF_df.to_csv('../Data/TEF_dataset.csv')\n",
    "#UNI_df.to_csv('../Data/UNI_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí ya tenemos los 35 archivos guardados en su correspondiente repositorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>21.370347</td>\n",
       "      <td>21.370347</td>\n",
       "      <td>20.997152</td>\n",
       "      <td>21.118277</td>\n",
       "      <td>1416627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>21.213212</td>\n",
       "      <td>21.383439</td>\n",
       "      <td>21.173927</td>\n",
       "      <td>21.259043</td>\n",
       "      <td>454050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>21.396540</td>\n",
       "      <td>21.946512</td>\n",
       "      <td>21.376898</td>\n",
       "      <td>21.926870</td>\n",
       "      <td>1385247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>21.959604</td>\n",
       "      <td>22.254232</td>\n",
       "      <td>21.874489</td>\n",
       "      <td>22.221495</td>\n",
       "      <td>584567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>22.260779</td>\n",
       "      <td>22.326252</td>\n",
       "      <td>22.031624</td>\n",
       "      <td>22.031624</td>\n",
       "      <td>509748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-13</th>\n",
       "      <td>38.860001</td>\n",
       "      <td>39.419998</td>\n",
       "      <td>38.740002</td>\n",
       "      <td>39.360001</td>\n",
       "      <td>403195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-14</th>\n",
       "      <td>39.200001</td>\n",
       "      <td>39.580002</td>\n",
       "      <td>39.060001</td>\n",
       "      <td>39.439999</td>\n",
       "      <td>485238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-15</th>\n",
       "      <td>39.419998</td>\n",
       "      <td>39.599998</td>\n",
       "      <td>38.740002</td>\n",
       "      <td>39.480000</td>\n",
       "      <td>736659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-16</th>\n",
       "      <td>39.540001</td>\n",
       "      <td>39.820000</td>\n",
       "      <td>39.320000</td>\n",
       "      <td>39.759998</td>\n",
       "      <td>552398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-17</th>\n",
       "      <td>39.560001</td>\n",
       "      <td>40.080002</td>\n",
       "      <td>39.520000</td>\n",
       "      <td>39.840000</td>\n",
       "      <td>535216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1631 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close   Volume  Dividends  \\\n",
       "Date                                                                         \n",
       "2018-01-02  21.370347  21.370347  20.997152  21.118277  1416627        0.0   \n",
       "2018-01-03  21.213212  21.383439  21.173927  21.259043   454050        0.0   \n",
       "2018-01-04  21.396540  21.946512  21.376898  21.926870  1385247        0.0   \n",
       "2018-01-05  21.959604  22.254232  21.874489  22.221495   584567        0.0   \n",
       "2018-01-08  22.260779  22.326252  22.031624  22.031624   509748        0.0   \n",
       "...               ...        ...        ...        ...      ...        ...   \n",
       "2024-05-13  38.860001  39.419998  38.740002  39.360001   403195        0.0   \n",
       "2024-05-14  39.200001  39.580002  39.060001  39.439999   485238        0.0   \n",
       "2024-05-15  39.419998  39.599998  38.740002  39.480000   736659        0.0   \n",
       "2024-05-16  39.540001  39.820000  39.320000  39.759998   552398        0.0   \n",
       "2024-05-17  39.560001  40.080002  39.520000  39.840000   535216        0.0   \n",
       "\n",
       "            Stock Splits  \n",
       "Date                      \n",
       "2018-01-02           0.0  \n",
       "2018-01-03           0.0  \n",
       "2018-01-04           0.0  \n",
       "2018-01-05           0.0  \n",
       "2018-01-08           0.0  \n",
       "...                  ...  \n",
       "2024-05-13           0.0  \n",
       "2024-05-14           0.0  \n",
       "2024-05-15           0.0  \n",
       "2024-05-16           0.0  \n",
       "2024-05-17           0.0  \n",
       "\n",
       "[1631 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACS_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
